#!/usr/bin/env python
# coding: utf-8

# <div class="alert alert-info">
# <h2> Комментарий от ревьюера</h2>
# Привет. Меня зовут Алина Гусева, я буду делать ревью к твоей работе по статистическому анализу данных. В дальнейшем предлагаю общаться на "ты".
#     
# Видно, что ты старался, делая проект. Все ключевые этапы проекта выполнены, в целом тебе удалось со всем справиться. Особенно хочется отметить, что соблюдена структура проекта, а код написан аккуратно. Есть, правда, несколько замечаний, которые нужно исправить.
#     
# Для того, чтобы и тебе и мне удобнее бы
#     ло ориентироваться в комментариях, я буду помечать их разными цветами:
# - красный цвет означает комментарии, которые требуют доработки. Как только ты их исправишь - проект будет принят;
# - желтый цвет - то, что в следующий раз можно будет сделать по-другому. На твое усмотрение можешь доделать маленькие правки сейчас или учесть замечание для выполнения следующих проектов;
# - зеленый цвет - очень элегантные и удачные решение, которые желательно использовать в дальнейшей работе.
# - синий цвет - информация
#     
# Предлагаю работать над проектом в диалоге: если ты что-то изменяешь или вносишь какие-то коррективы - выделяй это каким-нибудь цветом и пиши об этом мне. Так мне гораздо легче будет отследить сделанные изменения.
#     
# Также попрошу тебя не изменять и не удалять мои комментарии, чтобы проверка твоего самостоятельного проекта прошла оперативнее.
#     
#  
# </div>

# ## Исследование надёжности заёмщиков
# 
# Заказчик — кредитный отдел банка. Нужно разобраться, влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок. Входные данные от банка — статистика о платёжеспособности клиентов.
# 
# Результаты исследования будут учтены при построении модели **кредитного скоринга** — специальной системы, которая оценивает способность потенциального заёмщика вернуть кредит банку.

# ### Шаг 1. Откройте файл с данными и изучите общую информацию. 

# In[5]:


import pandas as pd
data=pd.read_csv('/datasets/data.csv')
print(data.info())
print(data.head(5))


# ### Вывод

# Таблица состоит из 12 столбцов и 21525 строк.
# Заметили пропуски значений в days_employed и total_income.
# Проанализировали типы данных во всех столбцах и их  количество: float64(2), int64(5), object(5)

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Молодец, хороший тон использовать метод info() для получения общей информации из таблицы.
#  Также верно сделаны выводы в контексте данного задания.
# 
# </div>

# ### Шаг 2. Предобработка данных

# ### Обработка пропусков

# In[6]:


print(len(data['days_employed'].unique()))


# В столбце стажа было найдено 19352 уникальных значения.
# Столбец имеет числовой тип данных, поэтому мы может его отсортировать и посмотреть на значения в концовке.

# In[7]:


print(data.sort_values(by='days_employed').tail(5))


# Видим, что в столбце стажа есть значения NaN. Это количественная переменная, поэтому можем оценить несколько вариантов:
# Сколько пропусков относительно всей таблицы? Если меньше 1 процента, то можно удалить эти строки.
# Если нет, то подставить либо среднее, либо медиану. Оценить что более логично поможет для отчета.

# In[8]:


print('В столбце со стажем пропущено {:.1%} значений'.format(data['days_employed'].isna().sum()/data['days_employed'].count()))


# Удалять нельзя, нужно заполнять.
# Пропуски в этом столбце могли появиться из-за того, что клиенты могли не указывать свой стаж работы.

# In[9]:


print('Среднее по стажу: {:.2f}'.format(data['days_employed'].mean()))
print('Медиана по стажу: {:.2f}'.format(data['days_employed'].median()))


# Среднее значение в данном случае не отображает верную информацию. У кого-то может быть огромный стаж и это может портить выборку. Среднее сильно завышено от реально возможных значений. Это тревожит, нужно проверить.
# 
# Также замечаю, что медиана по стажу у меня отрицательная. То есть в большинстве случаев у меня указан отрицательный стаж.
# Нужно оценить сколько таких значений, возможно ошибка при выгрузке.
# 

# In[10]:


print('Процент отрицательного стажа: {:.1%}'.format(data[data['days_employed']<0]['days_employed'].count()/data['days_employed'].count()))


# Меняю знак для отрицательного стажа. Ошибка могла возникнуть из-за разной логики слияния данных или при выгрузке.

# In[11]:


data['days_employed']=abs(data['days_employed'])
print('Процент отрицательного стажа: {:.1%}'.format(data[data['days_employed']<0]['days_employed'].count()/data['days_employed'].count()))


# In[12]:


print('Средний стаж одного человека в годах: {:.0f}'.format(data['days_employed'].mean()/365))


# Такого быть не может, оценим сколько таких значений в нашей таблице. Возьмем возраст каждого заёмщика и посчитаем какой максимальный стаж в днях у него может быть на данный момент начиная с 18 лет.

# In[13]:


print('Процент завышенного стажа: {:.1%}'.format(data[(data['days_employed']/365)>(data['dob_years']-18)]['days_employed'].count()/data['days_employed'].count()))


# На этом моменте было множество рассуждений и задан вопрос в канале проектов. Оказалось, что далее нам не требуется использовать этот столбец, поэтому осталяю так.
# Избавились от артефактов и возвращаемся к подсчёту нового среднего и медианы.

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Да, это действительно так. По какой-то причине ланные грузятся некорректно и в  таблице возникает очень много отрицательных значеий. Естесственно, такого быть не должно. Прежде всего нужно обработать их, а потом исктаь пути решения. Тебе верно подсказли, что для дальнейшего исследвания столбец не пригодится. В таком случае, можно сделать минимальную предобработку и сообщить о некорректности данных разработчику баз данных.
# 
# </div>

# In[14]:


print('Правильное среднее по стажу: {:.2f}'.format(data['days_employed'].mean()))
print('Правильная медиана по стажу: {:.2f}'.format(data['days_employed'].median()))


# При большом разбросе медиана более корректно отображает значение стажа

# In[15]:


data['days_employed']=data['days_employed'].fillna(data['days_employed'].median())
data['days_employed'].count()


# Замена прошла успешно, снова проверим среднее и медиану после замены.

# In[16]:


print('После замены седнее по просрочкам: {:.2f}'.format(data['days_employed'].mean()))
print('После замены медиана по просрочкам: {:.2f}'.format(data['days_employed'].median()))


# Среднее логичным образом снизилось. Медиана не изменилась.
# Переходим с столбцу с доходами.

# In[17]:


print(len(data['total_income'].unique()))


# В столбце доходов было найдено 19352 уникальных значения.
# Столбец имеет числовой тип данных, поэтому мы может его отсортировать и посмотреть на значения в концовке.

# In[18]:


print(data.sort_values(by='total_income').tail(5))


# Видим, что в столбце дохода есть значения NaN. Это количественная переменная, поэтому можем оценить несколько вариантов:
# Сколько пропусков относительно всей таблицы? Если меньше 1 процента, то можно удалить эти строки.
# Если нет, то подставить либо среднее, либо медиану. Оценить что более логично поможет для отчета.

# In[19]:


print('В столбце с доходами пропущено {:.1%} значений'.format(data['total_income'].isna().sum()/data['total_income'].count()))


# Удалять нельзя, нужно заполнять. 
# Пропуски в этом столбце могли появиться из-за того, что данные по доходам могли быть просто не предоставлены.

# In[20]:


print('Среднее по доходам: {:.2f}'.format(data['total_income'].mean()))
print('Медиана по доходам: {:.2f}'.format(data['total_income'].median()))


# Среднее значение в данном случае не отображает верную информацию. У кого-то может быть огромный доход и это может портить выборку.
# Делаю выбор в пользу медианы.

# In[21]:


data['total_income']=data['total_income'].fillna(data['total_income'].median())
data['total_income'].count()


# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# В принципе, у тебя верный подход. Но для более точной замены можно было предварительно сгруппировать данные(например, по типу занятости) и уже относительно этих групп заменять пропуски медианным или средним значением. Ведь зарплата у студента и госсслужащего отличается значительно, а сейчас мы все причешем под одну гребенку.
# </div> 

# In[22]:


print('После замены седнее по доходам: {:.2f}'.format(data['total_income'].mean()))
print('После замены медиана по доходам: {:.2f}'.format(data['total_income'].median()))


# Среднее логичным образом снизилось. Медиана не изменилась.
# Проверям информацию о всей таблице.

# In[23]:


data.info()


# ### Вывод

# Земена пропусков прошла успешно, данные не пострадали. Все столбцы заполнены.
# 
# Возможно было бы логичнее разделить медианы по типам в соответствии с возрастной группой, образованием и типом занятости. Такие выборки дали бы более точные значения медиан, но таких вариантов (если разделить хотя бы на два значения в каждом виде) получилось бы минимум 8.
# 
# Если задача потсавлена в короткие сроки, то это можно пропустить.

# ### Замена типа данных

# Нас попросили заменить вещественный тип на целый. Таких столбцов у нас всего два и для замены идеально подойдёт метод astype()
# Другие методы нет смысла использовать, потому что нам нужно отбросить только дробную часть числа. Это не строковый тип, и не временной. 

# In[24]:


data['days_employed']=data['days_employed'].astype('int')
data['total_income']=data['total_income'].astype('int')
data.info()


# ### Вывод

# После замены типа с вещественного на целочисленный у нас в таблице осталось только два типа данных. 7 столбцов с целыми числами, 5 со строками 

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Молодец, все столбцы имееют нужный тип данных, можно приступать к следующему шагу)
# </div>

# ### Обработка дубликатов

# У нас есть 5 столбцов со строковым типом данных. Нужно проверить их на потенциальные дубликаты. 

# In[25]:


from collections import Counter
Counter(data['education'])


# Очевидные дубли, которые отличаются только регистром. Возможно эта графа заполняется вручную пользователем, что может привести к ошибкам такого вида. Приведём все столбцы к нижнему регистру и проверим на уникальность.

# In[26]:


data['education']=data['education'].str.lower()
Counter(data['education'])


# Теперь всё хорошо

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Вот это замечание очень важно. В дальнейшем нужно не забывать приводить текстовый формат данных к единому виду
# 
# </div>

# In[27]:


Counter(data['family_status'])


# In[28]:


Counter(data['gender'])


# Был найден случайный пропуск, который можно легко восстановить зная Фамилию или Имя. У нас таких данных нет. Найдём и посмотрим на эту строку.

# In[29]:


print(data[data['gender']=='XNA'])


# Была единственная надежда на декрет. Но его здесь нет. Придётся удалить эту строку.

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Ошибка в данных, такое бывает. Конечно, такую строчку нужно удалять
# </div>

# In[30]:


data.drop(data[data['gender']=='XNA'].index, inplace = True) 
data.reset_index(drop=True)
print(data.info())


# In[31]:


Counter(data['gender'])


# Удаление произошло корректно

# In[32]:


Counter(data['income_type'])


# In[33]:


purpose_count=Counter(data['purpose'])
purpose_count


# In[34]:


print(Counter(data['children']))


# Были найдены артефакты с отрицательным количетсвом детей, их меньше 1 процента - можно удалить.

# <div class="alert alert-warning">
# <h2> Комментарий от ревьюера</h2>
# Также подозрительно много пар с количеством детей 20. При этом нет людей с 19,18,17... Скорее всего здесь тоже ошибка и значение необходимо поделить на 10.
# 
# </div>

# In[35]:


data.drop(data[data['children']<0].index, inplace = True) 
data.reset_index(drop=True)
print(data.info())


# ### Вывод

# В нашей таблице был только один строковый столбец заполнен ошибочно. Привели всё к одному регистру и проблема решилась. Также была найдена строка со случайной ошибкой в столбце пол, восстановить данные не удалось, удалили её.

# ### Лемматизация

# In[36]:


from pymystem3 import Mystem
m = Mystem()
purpose_lemma=[] #создал пустой список для накопления всех слов
for i in data['purpose']:
    for word in i.split():
        if word!=' ':
            purpose_lemma+=(m.lemmatize(word))
print(purpose_lemma[:10])


# После лемматизации получил список, посчитаем количество разных слов в приведенном списке

# In[37]:


purpose_lemma.sort()
Counter(purpose_lemma)


# ### Вывод

# Среди целей кредита чаще всего встречаются слова 'покупка','жилье','автомобиль','образование','недвижимость' и 'свадьба'.
# Это исследование поможет нам разделить наши цели всего на несколько типов.

# ### Категоризация данных

# In[38]:


from pymystem3 import Mystem
m = Mystem()
def lem(row):
    l=m.lemmatize(row)
    if 'автомобиль' in l:
        return 'автомобиль'
    elif 'свадьба' in l:
        return 'свадьба'
    elif 'образование' in l:
        return 'образование'
    elif 'жилье' or 'недвижимость' in l:
        return 'недвижимость'
data['purpose_type']=data['purpose'].apply(lem)
data['purpose_type'].value_counts()


# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Ура, лемматизация прошла успешно, можно двигаться к следующему шагу)
# 
# </div>

# In[39]:


data.info()


# Добавили новый столбец, после применения функции он оказался полностью заполнен

# ### Вывод

# Лемматизация позволила нам разделить цели получения кредита всего на 4 категории. Что позволит в дальнейшем оценить как цел влияет на задолженность.

# ### Шаг 3. Ответьте на вопросы

# - Есть ли зависимость между наличием детей и возвратом кредита в срок?

# In[40]:


print('Процент должников по всей таблице: {:.0%}'.format(data['debt'].sum()/data['debt'].count()))


# In[41]:


print('Должники сгруппированные по детям: \n',data.groupby('children')['debt'].count())


# В нашей таблице количество детей между клиентами распределенно неравномерно. ПОэтому будет логично проверять каждого внутри своей категории.

# In[42]:


children_unique=data['children'].unique()
children_unique.sort()
for i in children_unique:
    print('Процент просрочек с',i,'детьми: {:.2%}'.format(data[data['children']==i]['debt'].sum()/data[data['children']==i]['debt'].count()))


# ### Вывод

# Исследование внутри каждой группы показало, что процент просрочки прмерно совпадает с общим процентом просрочек. Наблюдается небольшой рост при увеличении количества детей.

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Да, заемщики без детей самые отвтственные.
# </div>

# - Есть ли зависимость между семейным положением и возвратом кредита в срок?

# In[43]:


print('Должники сгруппированные по семейному положению: \n',data.groupby('family_status')['debt'].count())


# В нашей таблице семейные статус между клиентами распределен неравномерно. ПОэтому будет логично проверять каждого внутри своей категории.

# In[44]:


family_status_unique=data['family_status'].unique()
family_status_unique.sort()
for i in family_status_unique:
    print('Процент просрочек с семейным статусом',i,': {:.2%}'.format(data[data['family_status']==i]['debt'].sum()/data[data['family_status']==i]['debt'].count()))


# ### Вывод

# Исследование внутри каждой группы показало, что процент просрочки прмерно совпадает с общим процентом просрочек. С положительной динамикой выделяются вдовцы, затем разведенные и женатые. Больше всего просрочек у не женатых или живущих в гражданском браке.

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Молодец, вывод сделан правильный!
# 
# </div>

# - Есть ли зависимость между уровнем дохода и возвратом кредита в срок?

# In[45]:


print('Максимальная зарплата: {:.0f}'.format(data['total_income'].max()))
print('Средняя зарплата: {:.0f}'.format(data['total_income'].mean()))
print('Медиана по зарплате: {:.0f}'.format(data['total_income'].median()))
print('Минимальная зарплата: {:.0f}'.format(data['total_income'].min()))


# Оценив разброс зарплат можно разделить всех клиентов на несколько категорий.

# In[46]:


def income(x):
    if x<50000 :
        return 'низкий'
    elif x<100000:
        return 'средний'
    elif x<150000:
        return 'выше среднего'
    elif x<200000:
        return 'выcокий'
    else:
        return 'очень выcокий'
data['income_level']=data['total_income'].apply(income)
data['income_level'].value_counts()


# В нашей таблице уровень дохода между клиентами распределен неравномерно. ПОэтому будет логично проверять каждого внутри своей категории.

# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# Здесь все зависит от того, как ты разделишь на группы. Лучше всего использовать квантиль, чтобы группы получились равные по количеству людей.
# </div>

# In[47]:


income_level_unique=['низкий','средний','выше среднего','выcокий','очень выcокий']
for i in income_level_unique:
    print('Процент просрочек клиентов, у которых уровень дохода',i,': {:.2%}'.format(data[data['income_level']==i]['debt'].sum()/data[data['income_level']==i]['debt'].count()))


# ### Вывод

# На удивление, но больше всего просрочек у людей с высоким уровнем дохода. У нас наблюдается обратная зависимость. Исключение - клиенты с очень высоким уровнем дохода.

# - Как разные цели кредита влияют на его возврат в срок?

# In[48]:


purpose_type_unique=data['purpose_type'].unique()
purpose_type_unique.sort()
for i in purpose_type_unique:
    print('Процент клиентов, у которых целью кредита является',i,': {:.2%}'.format(data[data['purpose_type']==i]['debt'].sum()/data[data['purpose_type']==i]['debt'].count()))


# ### Вывод

# Меньше просрочек бывает по направлению недвижимости и свадьбы, больше с образованием и автомобилями.

# ### Шаг 4. Общий вывод

# На входе мы получили большую таблицу, в которой были пропуски и дубли. В таблице оказалось много артефактов, такие как отрицательный стаж, отрицательное количество детей, огромный стаж в несколько сотен лет. После небольшой обработки данных, удаления дублей и лемматизации целей мы смогли категоризировать данные и ответить на поставленные вопросы максимально точно. В ходе выполнения мною было добавлено несколько столбцов, в которые я сохранял категории. 
# 
# Конструкцию try-expect логичнее было бы использовать для перевода типа из 'объект' в 'число'
# 
# В моей таблице ещё остались артефакты, такие как огромный стаж.

# In[49]:


data.head(5)


# <div class="alert alert-success">
# <h2> Комментарий от ревьюера</h2>
# 
# Поздравляю с первым успешным проектом!
# 
# - Ты хорошо делаешь выводы и анализируешь результаты.
#     
# - Код написан аккуратно и качественно, видно, что есть какой-то определенный бэкграунд.
# 
# - Соблюдена структура проекта, было приятно проверять:)
#     
# - Все написано четко и по делу
# 
#     
#  Желаю дальнейших успехов!
# 
# 
# </div>
# 

# ### Чек-лист готовности проекта
# 
# Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter.

# - [x]  открыт файл;
# - [x]  файл изучен;
# - [x]  определены пропущенные значения;
# - [x]  заполнены пропущенные значения;
# - [x]  есть пояснение, какие пропущенные значения обнаружены;
# - [x]  описаны возможные причины появления пропусков в данных;
# - [x]  объяснено, по какому принципу заполнены пропуски;
# - [x]  заменен вещественный тип данных на целочисленный;
# - [x]  есть пояснение, какой метод используется для изменения типа данных и почему;
# - [x]  удалены дубликаты;
# - [x]  есть пояснение, какой метод используется для поиска и удаления дубликатов;
# - [x]  описаны возможные причины появления дубликатов в данных;
# - [x]  выделены леммы в значениях столбца с целями получения кредита;
# - [x]  описан процесс лемматизации;
# - [x]  данные категоризированы;
# - [x]  есть объяснение принципа категоризации данных;
# - [x]  есть ответ на вопрос: "Есть ли зависимость между наличием детей и возвратом кредита в срок?";
# - [x]  есть ответ на вопрос: "Есть ли зависимость между семейным положением и возвратом кредита в срок?";
# - [x]  есть ответ на вопрос: "Есть ли зависимость между уровнем дохода и возвратом кредита в срок?";
# - [x]  есть ответ на вопрос: "Как разные цели кредита влияют на его возврат в срок?";
# - [x]  в каждом этапе есть выводы;
# - [x]  есть общий вывод.
